{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r2d2_hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JYE6sm9H5rc"
      },
      "source": [
        "# Part 1: Face Detector Using PCA\n",
        "### In the first section, you will use PCA to implement a face detector. \n",
        "If you are unfamilar with PCA, [here](https://https://www.youtube.com/watch?v=fkf4IBRSeEc) is a great introduction video.\n",
        "\n",
        "![alt text](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/56a6db0b-e295-4763-9e62-740e82eda043/d4hxkdr-219d905e-c623-4295-b7b0-e736c54b5e53.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOiIsImlzcyI6InVybjphcHA6Iiwib2JqIjpbW3sicGF0aCI6IlwvZlwvNTZhNmRiMGItZTI5NS00NzYzLTllNjItNzQwZTgyZWRhMDQzXC9kNGh4a2RyLTIxOWQ5MDVlLWM2MjMtNDI5NS1iN2IwLWU3MzZjNTRiNWU1My5wbmcifV1dLCJhdWQiOlsidXJuOnNlcnZpY2U6ZmlsZS5kb3dubG9hZCJdfQ.WhA2LoDpAxyDb0gJjH5giOimM4aDKj3XT6SzMIplAvE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Odiek4GiHP7"
      },
      "source": [
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtU2V6s8iMNE"
      },
      "source": [
        "## 1. Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quBImCIGNcw_"
      },
      "source": [
        "* Download the faces.p from course website or run the following code, if you are using the colab, you could \n",
        "upload this file to the colab or google drive.\n",
        "\n",
        "* faces.p contains 2000 unique faces and each face has the size of 64 x 64, run the following code to take a look at the data structure and some sample faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TizSyxebILuv"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1DgsqLxAYSnA3Yd9tODPbvSfEXR-A6nml\" -O faces.p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U543Anm7iKGH"
      },
      "source": [
        "faces = pickle.load(open(\"faces.p\", \"rb\"))\n",
        "print(\"Shape: \", faces.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEw79n6tOWtx"
      },
      "source": [
        "face = faces[0] # change the index to check other faces\n",
        "plt.imshow(face)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6StGe1hisZD"
      },
      "source": [
        "### **Flatten the faces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSB0KhRkPFSc"
      },
      "source": [
        "Flatten the 2D images to 1D vector, that is (64, 64) to (4096, )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcucHBhfin5z"
      },
      "source": [
        "def flatten_faces(faces):\n",
        "  '''TODO\n",
        "  Input array: (2000, 64, 64)\n",
        "  Output array: (2000, 4096)\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "face_vectors = flatten_faces(faces)\n",
        "print(\"Flatten Face Shape: \", face_vectors.shape)\n",
        "assert face_vectors.shape == (2000, 4096)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VGnAvvqi-Az"
      },
      "source": [
        "### **Calculate the average face**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHtNmgS5i9LR"
      },
      "source": [
        "def cal_average_face(face_vectors):\n",
        "  '''TODO\n",
        "  Input array: (2000, 4096)\n",
        "  Output array: (4096, )\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "average_face = cal_average_face(face_vectors)\n",
        "print(\"Average Face Shape: \", average_face.shape)\n",
        "assert average_face.shape == (4096, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Ujvp5lkvOY"
      },
      "source": [
        "# Show the average face\n",
        "plt.imshow(average_face.reshape(64, 64), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp2R_Nonkq7u"
      },
      "source": [
        "# Do not change the following line, you need to submit average_face.p to gradescope\n",
        "# If you are using colab, it will show up on the left side, remember to download it\n",
        "pickle.dump(average_face, open('average_face.p', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeD2asQgkwjU"
      },
      "source": [
        "## 2. Compute the Eigenfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw6eFzd9k774"
      },
      "source": [
        "### **Calculate the covariance matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1rjp7nlRoza"
      },
      "source": [
        "In this section, you are required to calculate the [covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix) of the face vector using the following equation\n",
        "\n",
        "$$Covariance = A \\cdot A^T$$\n",
        "\n",
        "where A in this case is the orginal face vector minus the average face vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta8aTxIPk7AN"
      },
      "source": [
        "def cal_covariance(A):\n",
        "  '''TODO\n",
        "  Input: (2000, 4096)\n",
        "  Output: (2000, 2000)\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "A = face_vectors - average_face\n",
        "C = cal_covariance(A)\n",
        "\n",
        "assert C.shape == (2000, 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-4IeBjYlkbc"
      },
      "source": [
        "### **Compute the Eigenvectors**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO6SvTHwWNTW"
      },
      "source": [
        "Implement the `cal_eigenvectors()` which takes in the covariance matrix and return the eigenvectors **sorted** by the **descending** order of the eigenvalue. It may take around 30 seconds for calculation.\n",
        "\n",
        "You could use `np.linalg` to compute the eigenvector, please refer to the offical document for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHOkRZlulvkE"
      },
      "source": [
        "def cal_eigenvectors(C):\n",
        "  '''TODO\n",
        "  Input: (2000, 2000)\n",
        "  Output: (2000, 2000)\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "eigenvectors = cal_eigenvectors(C)\n",
        "assert eigenvectors.shape == (2000, 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXQh6qEEXCXe"
      },
      "source": [
        "Implement the `cal_eigenfaces(eigenvectors)` which transform the eigenvectors to eigenfaces using the formula:\n",
        "$$eigenfaces = (A^T \\cdot eigenvectors)^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzx3jDplxRX"
      },
      "source": [
        "def vector2face(eigenvectors, A):\n",
        "  '''TODO\n",
        "  Input: (2000, 2000)\n",
        "  Output: (2000, 4096)\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "eigenfaces = vector2face(eigenvectors, A)\n",
        "\n",
        "assert eigenfaces.shape == (2000, 4096)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmcHj4g9qTpe"
      },
      "source": [
        "show the eigenface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9dJ1XZDqTMD"
      },
      "source": [
        "eigface_id = 0 # Change the index to show different eigenfaces\n",
        "plt.imshow(eigenfaces[eigface_id].reshape((64, 64)), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOS3Mc3rdco"
      },
      "source": [
        "# Do not change the following line, you need to submit eigenfaces.p to gradescope\n",
        "# If you are using colab, it will show up on the left side, remember to download it\n",
        "pickle.dump(eigenfaces, open('eigenfaces.p', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Tye8Mhrhg5"
      },
      "source": [
        "## Face Space Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvexf5H4saN8"
      },
      "source": [
        "### **Projection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9Ib0goYjfh"
      },
      "source": [
        "In this section, you need to implement a function which could project any images into the eigenface spans.\n",
        "\n",
        "It includes two steps:\n",
        "\n",
        "* Compute the weights of each eigenfaces, and **normalize** it using L1 Norm vector.$$weight = eigenfaces \\cdot target vector^T$$\n",
        "\n",
        "* Mutiply the weight with the eigenfaces using $$weight^T \\cdot eigenfaces$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSaSoUtpruUQ"
      },
      "source": [
        "def preprocess(target, average_face):\n",
        "  if len(target.shape) == 3:\n",
        "      target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
        "  # resize\n",
        "  target_resized = cv2.resize(target, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "  # reshape\n",
        "  target_vector = target_resized.reshape((64*64,))\n",
        "  # substract mean\n",
        "  target_vector = target_vector - average_face\n",
        "  return target_vector\n",
        "    \n",
        "def proj2face_space(target_vector, eigenfaces):\n",
        "  '''TODO'''\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7HchpggtO0p"
      },
      "source": [
        "target = cv2.imread('FILENAME') # replace the name with any test images\n",
        "target_vector = preprocess(target, average_face)\n",
        "face_space_vector = proj2face_space(target_vector, eigenfaces)\n",
        "print(face_space_vector.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtbj85hzq8n1"
      },
      "source": [
        "plt.title('Original Image')\n",
        "plt.imshow(target_vector.reshape((64, 64)), cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Face Space Image')\n",
        "plt.imshow(face_space_vector.reshape((64, 64)), cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFV__AGssm67"
      },
      "source": [
        "### **Compute the Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vetg6_oKeisA"
      },
      "source": [
        "Implement the `dist2face_space(target_vector, face_space_vector)` which returns the euclidean distance between the two vectors. You may use the [np.linalg](https://numpy.org/doc/stable/reference/routines.linalg.html) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LlpT0MsZxY"
      },
      "source": [
        "def dist2face_space(target_vector, face_space_vector):\n",
        "    '''TODO: return a float'''\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dufLe9gRtFNO"
      },
      "source": [
        "print(dist2face_space(target_vector, face_space_vector))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCOSqrtqQcvW"
      },
      "source": [
        "After you finish everything above, you could now apply this face detector on the R2D2. Put the eigenfaces.p and average_face.p in the same folder of the given scripts and run `pca_face_detection()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjQm4zFAIYVG"
      },
      "source": [
        "# Part 2: Mask Detection\n",
        "### In this section, you will implement the mask detector using different methods.\n",
        "\n",
        "![alt text](https://i.imgflip.com/43hc09.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDrS6KVtIc9u"
      },
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rh0tlKBPb-C"
      },
      "source": [
        "## Download the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yEswIcfWvay"
      },
      "source": [
        "Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZTeb2zHQpgY"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1ouMOxaDNNr-U7E2DD3Y6wLlyeVb8qnr0\" -O train_data.p\n",
        "data_list = pickle.load(open(\"train_data.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKVH6DRKWxeO"
      },
      "source": [
        "Test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x__kgFbQWur2"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=16CCS6DiAzFwCT1165ogvKVf9JwajOAHm\" -O test_images.p\n",
        "test_images = pickle.load(open(\"test_images.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "off-m630cvum"
      },
      "source": [
        "### Get a View of how dataset looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_eug-JMTPyV"
      },
      "source": [
        "Run the following code to check the dataset.\n",
        "\n",
        "The given training dataset contains 4602 examples and example is a human face with a label (good or bad) to denote whether there is a mask on the face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkLVp8-hRixm"
      },
      "source": [
        "print(\"The size of the dataset is: \", len(data_list))\n",
        "print(\"\\n The Structure of the data: \", '\\n', type(data_list[0]))\n",
        "print(data_list[-1])\n",
        "print(\"\\n Show some of the samples\")\n",
        "f, axarr = plt.subplots(2,2, figsize=(10,10))\n",
        "axarr[0, 0].imshow(data_list[1]['image'])\n",
        "axarr[0, 0].title.set_text(data_list[0]['label'])\n",
        "axarr[0, 1].imshow(data_list[2]['image'])\n",
        "axarr[0, 1].title.set_text(data_list[2]['label'])\n",
        "axarr[1, 0].imshow(data_list[-1]['image'])\n",
        "axarr[1, 0].title.set_text(data_list[-1]['label'])\n",
        "axarr[1, 1].imshow(data_list[-2]['image'])\n",
        "axarr[1, 1].title.set_text(data_list[-3]['label'])\n",
        "f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy71-MqgZZ3q"
      },
      "source": [
        "## Preprocessing of the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4di7_f-QZjCQ"
      },
      "source": [
        "### Distribution of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXGGL_AMTZnO"
      },
      "source": [
        "### Count the number of different classes ###\n",
        "Num_of_classes = 0\n",
        "classes = {}\n",
        "for sample in data_list:\n",
        "  if sample['label'] not in classes:\n",
        "    classes[sample['label']] = 1\n",
        "  else:\n",
        "    classes[sample['label']] += 1\n",
        "print(\"Num. of Different Classes: \", classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCbL3TcDdfBb"
      },
      "source": [
        "### Distribution of the Size of the Images ###\n",
        "image_size = []\n",
        "for sample in data_list:\n",
        "  image_data = sample['image']\n",
        "  size = image_data.shape[0] * image_data.shape[1]\n",
        "  image_size.append(size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6RynTMweX2z"
      },
      "source": [
        "print(\"Median Size of Images: \", np.median(image_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9bRDJBrhPp8"
      },
      "source": [
        "### Image Preprocessing\n",
        "For this section, we will preprocess the image data according to the following steps\n",
        "*   Convert gray image to RGB\n",
        "*   Resize the image to 128 * 128\n",
        "*   Scale the value of each pixel from [0, 255] to [-1, 1]\n",
        "\n",
        "You may find the opencv API is helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlMUu2uShnA0"
      },
      "source": [
        "### Images & Labels Split ###\n",
        "label2int = {\"good\": 1, \"bad\": 0}\n",
        "IMAGES = []\n",
        "LABELS = []\n",
        "for sample in data_list:\n",
        "  IMAGES.append(sample['image'])\n",
        "  LABELS.append(label2int[sample['label']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbpV_Q-h1tM"
      },
      "source": [
        "### Preprocess the Image ###\n",
        "def preprocess(image):\n",
        "  '''TODO\n",
        "  Preprocess the input image:\n",
        "  1. convert the gray-scale (2D) image to RGB (3D)\n",
        "  2. Resize the image to (128, 128, 3)\n",
        "  3. Scale the value of each pixel from [0, 255] to [-1, 1]\n",
        "  '''\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQuHlutBi_2X"
      },
      "source": [
        "### Process the Raw Image ###\n",
        "processed_IMAGES = []\n",
        "for image in IMAGES:\n",
        "  processed_IMAGES.append(preprocess(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf8i0zjcMElW"
      },
      "source": [
        "### Train / Validation Split\n",
        "Now we split the dataset to train and dev set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQ9FDEBL71d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(processed_IMAGES, LABELS, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNx34d19TQtB"
      },
      "source": [
        "## Baseline - Perceptron\n",
        "For the baseline model, we simply flatten the image data and utlize Perceptron as our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGEXe3TITN3_"
      },
      "source": [
        "def flatten(images):\n",
        "  '''TODO: Flatten the Image Data\n",
        "  Input: (128, 128, 3)\n",
        "  Output: (49152,)\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "X_train_flatten = flatten(X_train)\n",
        "X_val_flatten = flatten(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COObNGefbI4t"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "### TODO: Use Perceptron to fit the training data ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaSQULVcX2Wo"
      },
      "source": [
        "### Evaluate the performance on the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wMpAteOWsBj"
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=16CCS6DiAzFwCT1165ogvKVf9JwajOAHm\" -O test_images.p\n",
        "test_images = pickle.load(open(\"test_images.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Y_fl1faez4"
      },
      "source": [
        "You will need to preprocess these test images and predict the label for each images (1: good, 2: bad) \n",
        "\n",
        "and save your predictions in a list [0, 1, 1, ...]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkk9QAeUa6Ay"
      },
      "source": [
        "###TODO: Use your perceptron model to predict on the test images###\n",
        "prediction = []\n",
        "# Do not change the following line, you need to submit perceptron.p to gradescope\n",
        "# If you are using colab, it will show up on the left side, remember to download it\n",
        "pickle.dump(prediction, open(\"perceptron.p\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM2bCnPDb3Au"
      },
      "source": [
        "## Build Your Own CNN Model\n",
        "To improve the performance of our mask detector, we plan to build a CNN model using keras. A suggested architecture is shown as follows, but feel free to modify it by adding or eliminating layers. The autograder is based on your final accuracy.\n",
        "\n",
        "\n",
        "* Convolution with 32 filters with kernel size 7x7 followed by ReLU activation \n",
        "function, input shape (128, 128, 3);\n",
        "* Max Pool with filter size/pool size = 7 and stride = 4;\n",
        "* Convolution with 16 filters with kernel size 5x5 followed by ReLU activation function;\n",
        "* Max Pool with filter size/pool size = 7 and stride = 4;\n",
        "* Flatten layer to transform 3D layers to a single tensor/vector;\n",
        "* Fully Connected with 64 neurons and ReLU activation function\n",
        "* Fully Connected with 2 neurons and softmax activation function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2rOyGZzb2J0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZBSwED5ad4o"
      },
      "source": [
        "model = Sequential()\n",
        "num_classes = 2\n",
        "\n",
        "# # TODO: Conv1\n",
        "\n",
        "# # TODO: Conv2\n",
        "\n",
        "# # TODO: Flatten the layer\n",
        "\n",
        "# # TODO: Add the intermediate fully connected layers (Dense in keras)\n",
        "\n",
        "# # TODO: Add the final fully connected layer with the softmax activation function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu3wDDr1bBGy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4WY4xVgbzs8"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YrE_1LBd04q"
      },
      "source": [
        "### Ready For Training\n",
        "Before training, we need to first make sure the training data is an array with the correct size of our model's input. We also need to convert our labels to one hot type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9cXgmExdQ8U"
      },
      "source": [
        "def convert2onehot(labels):\n",
        "  result = []\n",
        "  for label in labels:\n",
        "    if label == 1:\n",
        "      result.append([1, 0])\n",
        "    else:\n",
        "      result.append([0, 1])\n",
        "  return np.array(result)\n",
        "\n",
        "X_train_array = np.array(X_train)\n",
        "X_val_array = np.array(X_val)\n",
        "y_train_onehot = convert2onehot(y_train)\n",
        "y_val_onehot = convert2onehot(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A-iUn0ac-pm"
      },
      "source": [
        "model.fit(X_train_array, y_train_onehot, batch_size=16, epochs=10, validation_data=(X_val_array, y_val_onehot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6YP10CUgG-u"
      },
      "source": [
        "### Evaluate on test images\n",
        "Again, evaluate the performance of your model on the test images and save your predictions into a list `[0, 1, 0, 0, ...]`.\n",
        "\n",
        "Note that you need to convert the one-hot prediction to the original labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxDxUcrQDSHA"
      },
      "source": [
        "###TODO: Use the CNN model to predict on the test images###\n",
        "prediction = []\n",
        "# Do not change the following line, you need to submit cnn.p to gradescope\n",
        "# If you are using colab, it will show up on the left side, remember to download it\n",
        "pickle.dump(prediction, open(\"cnn.p\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZPdHb-ehejn"
      },
      "source": [
        "## Advanced CNN Model using ImageNet\n",
        "To further enhance the ability of R2D2, we decided to use some well designed network architectures, aka, Imagenet. There are bunch of imagenets embedded in keras and you could follow the examples from [official document](https://keras.io/api/applications/) and fine tune these model on our mask detection task.\n",
        "\n",
        "Once you construct a excellent model, remember to save the model configuration and weight, as well as evaluate on the test images and upload to the leaderboard to compete with your classmates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFpkgJCILqpd"
      },
      "source": [
        "###TODO: Use your best model to predict on the test images###\n",
        "prediction = []\n",
        "# Do not change the following line, you need to submit best.p to gradescope\n",
        "# If you are using colab, it will show up on the left side, remember to download it\n",
        "pickle.dump(prediction, open(\"best.p\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmOQSUkZM727"
      },
      "source": [
        "###Save your model and weight\n",
        "model_json = model.to_json()\n",
        "\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"weight.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4SmIfJLNW8L"
      },
      "source": [
        "Now it's time to apply your mask detector on the R2D2, put your model and weight in the same folder of the given scripts and turn on your raspberry pi, you should be able to see a real time mask detector. Record a short video to show the performance of your model."
      ]
    }
  ]
}
